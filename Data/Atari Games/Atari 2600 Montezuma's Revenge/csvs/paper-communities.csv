title,communities,metric,paper_date,communities_name
First return then explore@@@Go-Explore,7,43791,2020-04-27,set()
Go-Explore: a New Approach for Hard-Exploration Problems@@@Go-Explore,7,43763,2019-01-30,set()
Agent57: Outperforming the Atari Human Benchmark@@@Agent57,2,9352.01,2020-03-30,"{'Google', 'Université de Montréal', 'Stanford University'}"
Exploration by Random Network Distillation@@@RND,4,8152,2018-10-30,"{'OpenAI', 'University of California, Berkeley', 'University of Edinburgh'}"
Contingency-Aware Exploration in Reinforcement Learning@@@A2C+CoEX,6+1,6635,2018-11-05,"{'Carnegie Mellon University', 'University of Michigan', 'Google', 'University of Cambridge', 'University of Alberta'}"
Count-Based Exploration with Neural Density Models@@@DQN-PixelCNN,2+1,3705.5,2017-03-03,"{'Carnegie Mellon University', 'Stanford University', 'Université de Montréal', 'Google', 'University of Cambridge', 'University of Alberta'}"
Unifying Count-Based Exploration and Intrinsic Motivation@@@DDQN-PC,2+1,3459,2016-06-06,"{'Carnegie Mellon University', 'Stanford University', 'Université de Montréal', 'Google', 'University of Cambridge', 'University of Alberta'}"
Count-Based Exploration in Feature Space for Reinforcement Learning@@@Sarsa-φ-EB,8,2745.4,2017-06-25,{'Australian National University'}
Large-Scale Study of Curiosity-Driven Learning@@@Intrinsic Reward Agent,4,2504.6,2018-08-13,"{'OpenAI', 'University of California, Berkeley', 'University of Edinburgh'}"
Distributed Prioritized Experience Replay@@@Ape-X,1,2500.0,2018-03-02,"{'University of Alberta', 'Google', 'University of Cambridge', 'Carnegie Mellon University'}"
Recurrent Experience Replay in Distributed Reinforcement Learning@@@R2D2,2+1,2061.3,2019-05-01,"{'Carnegie Mellon University', 'Stanford University', 'Université de Montréal', 'Google', 'University of Cambridge', 'University of Alberta'}"
Count-Based Exploration with the Successor Representation@@@DQN+SR,1,1778.8,2018-07-31,"{'University of Alberta', 'Google', 'University of Cambridge', 'Carnegie Mellon University'}"
Count-Based Exploration with the Successor Representation@@@DQNMMCe+SR,1,1778.6,2018-07-31,"{'University of Alberta', 'Google', 'University of Cambridge', 'Carnegie Mellon University'}"
Self-Imitation Learning@@@A2C + SIL,5,1100,2018-06-14,"{'Microsoft', 'Duke University', 'University of California, Santa Barbara'}"
Mastering Atari with Discrete World Models@@@DreamerV2,1,650,2020-10-05,"{'University of Alberta', 'Google', 'University of Cambridge', 'Carnegie Mellon University'}"
Count-Based Exploration in Feature Space for Reinforcement Learning@@@Sarsa-ε,8,399.5,2017-06-25,{'Australian National University'}
Unifying Count-Based Exploration and Intrinsic Motivation@@@A3C-CTS,2+1,273.7,2016-06-06,"{'Carnegie Mellon University', 'Stanford University', 'Université de Montréal', 'Google', 'University of Cambridge', 'University of Alberta'}"
@@@SARSA,,,,set()
Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models@@@MP-EB,10,142,2015-07-03,set()
Deep Exploration via Bootstrapped DQN@@@Bootstrapped DQN,2,100,2016-02-15,"{'Google', 'Université de Montréal', 'Stanford University'}"
Massively Parallel Methods for Deep Reinforcement Learning@@@Gorila,1+2+3,84,2015-07-15,"{'Carnegie Mellon University', 'Stanford University', 'Université de Montréal', 'Google', 'University of Cambridge', 'University of Alberta'}"
#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning@@@TRPO-hash,,,,set()
Asynchronous Methods for Deep Reinforcement Learning@@@A3C FF hs,2+1,67,2016-02-04,"{'Carnegie Mellon University', 'Stanford University', 'Université de Montréal', 'Google', 'University of Cambridge', 'University of Alberta'}"
Noisy Networks for Exploration@@@NoisyNet-Dueling,2,57,2017-06-30,"{'Google', 'Université de Montréal', 'Stanford University'}"
Asynchronous Methods for Deep Reinforcement Learning@@@A3C FF (1 day) hs,2+1,53,2016-02-04,"{'Carnegie Mellon University', 'Stanford University', 'Université de Montréal', 'Google', 'University of Cambridge', 'University of Alberta'}"
Prioritized Experience Replay@@@Prior hs,1,51,2015-11-18,"{'University of Alberta', 'Google', 'University of Cambridge', 'Carnegie Mellon University'}"
Deep Reinforcement Learning with Double Q-learning@@@DQN hs,1,47,2015-09-22,"{'University of Alberta', 'Google', 'University of Cambridge', 'Carnegie Mellon University'}"
Deep Reinforcement Learning with Double Q-learning@@@DDQN (tuned) hs,1,42,2015-09-22,"{'University of Alberta', 'Google', 'University of Cambridge', 'Carnegie Mellon University'}"
Asynchronous Methods for Deep Reinforcement Learning@@@A3C LSTM hs,2+1,41,2016-02-04,"{'Carnegie Mellon University', 'Stanford University', 'Université de Montréal', 'Google', 'University of Cambridge', 'University of Alberta'}"
Deep Reinforcement Learning with Double Q-learning@@@Prior+Duel hs,1,24,2015-09-22,"{'University of Alberta', 'Google', 'University of Cambridge', 'Carnegie Mellon University'}"
Dueling Network Architectures for Deep Reinforcement Learning@@@Duel hs,1,22,2015-11-20,"{'University of Alberta', 'Google', 'University of Cambridge', 'Carnegie Mellon University'}"
The Arcade Learning Environment: An Evaluation Platform for General Agents@@@Best Learner,1,10.7,2012-07-19,"{'University of Alberta', 'Google', 'University of Cambridge', 'Carnegie Mellon University'}"
Increasing the Action Gap: New Operators for Reinforcement Learning@@@Persistent AL,2+1,1.72,2015-12-15,"{'Carnegie Mellon University', 'Stanford University', 'Université de Montréal', 'Google', 'University of Cambridge', 'University of Alberta'}"
Increasing the Action Gap: New Operators for Reinforcement Learning@@@Advantage Learning,2+1,0.42,2015-12-15,"{'Carnegie Mellon University', 'Stanford University', 'Université de Montréal', 'Google', 'University of Cambridge', 'University of Alberta'}"
Implicit Quantile Networks for Distributional Reinforcement Learning@@@IQN,2+1,0,2018-06-14,"{'Carnegie Mellon University', 'Stanford University', 'Université de Montréal', 'Google', 'University of Cambridge', 'University of Alberta'}"
"Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model@@@MuZero",2+1,0.00,2019-11-19,"{'Carnegie Mellon University', 'Stanford University', 'Université de Montréal', 'Google', 'University of Cambridge', 'University of Alberta'}"
IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures@@@IMPALA (deep),2,0.00,2018-02-05,"{'Google', 'Université de Montréal', 'Stanford University'}"
Evolving simple programs for playing Atari games@@@CGP,9,0,2018-06-14,"{'University of York', 'University of Toulouse'}"
Policy Optimization With Penalized Point Probability Distance: An Alternative To Proximal Policy Optimization@@@POP3D,11,0,2018-07-02,{'Xiaomi'}
Distributional Reinforcement Learning with Quantile Regression@@@QR-DQN-1,2+1,0,2017-10-27,"{'Carnegie Mellon University', 'Stanford University', 'Université de Montréal', 'Google', 'University of Cambridge', 'University of Alberta'}"
