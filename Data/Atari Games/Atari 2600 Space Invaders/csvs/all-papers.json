[{"title": "Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model@@@MuZero", "authors": ["Julian Schrittwieser", "Ioannis Antonoglou", "Thomas Hubert", "Karen Simonyan", "Laurent Sifre", "Simon Schmitt", "Arthur Guez", "Edward Lockhart", "Demis Hassabis", "Thore Graepel", "Timothy P. Lillicrap", "David Silver"], "affiliations": ["", "", "", "", "", "", "", "", "", "", "", ""], "paper_date": "2019-11-19", "metric": "74335.30"}, {"title": "Distributed Prioritized Experience Replay@@@Ape-X", "authors": ["Dan Horgan", "John Quan", "David Budden", "Gabriel Barth-Maron", "Matteo Hessel", "H Van Hasselt", "Hado van Hasselt", "David Silver"], "affiliations": ["Google", "Google", "Google", "Google", "Google", "Google", "Google", "Google"], "paper_date": "2018-03-02", "metric": "54681"}, {"title": "Agent57: Outperforming the Atari Human Benchmark@@@Agent57", "authors": ["Adri\u00e0 Puigdom\u00e8nech Badia", "Bilal Piot", "Steven Kapturowski", "Pablo Sprechmann", "Alex Vitvitskyi", "Daniel Guo", "Charles Blundell"], "affiliations": ["Google", "", "", "", "", "", ""], "paper_date": "2020-03-30", "metric": "48680.86"}, {"title": "Fully Parameterized Quantile Function for Distributional Reinforcement Learning@@@FQF", "authors": ["Derek C Yang", "Li Zhao", "Zichuan Lin", "Tao Qin", "Jiang Bian", "Tie-Yan Liu"], "affiliations": ["University of California, San Diego", "Microsoft", "Tsinghua University", "Microsoft", "Microsoft", "Microsoft"], "paper_date": "2019-11-05", "metric": "46498.3"}, {"title": "IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures@@@IMPALA (deep)", "authors": ["Lasse Espeholt", "Hubert Soyer", "R\u00e9mi Munos", "Karen Simonyan", "Vlad Mnih", "Volodymyr Mnih", "Tom Ward", "Yotam Doron", "Vlad Firoiu", "Tim Harley", "Iain Dunning", "Shane Legg", "Koray Kavukcuoglu"], "affiliations": ["", "", "", "", "Google", "Google", "", "", "Google", "", "Google", "", ""], "paper_date": "2018-02-05", "metric": "43595.78"}, {"title": "Recurrent Experience Replay in Distributed Reinforcement Learning@@@R2D2", "authors": ["Steven Kapturowski", "Georg Ostrovski", "John Quan", "R\u00e9mi Munos", "Will Dabney"], "affiliations": ["", "Google", "Google", "Google", "Google"], "paper_date": "2019-05-01", "metric": "43223.4"}, {"title": "Implicit Quantile Networks for Distributional Reinforcement Learning@@@IQN", "authors": ["Will Dabney", "Georg Ostrovski", "David Silver", "R\u00e9mi Munos"], "affiliations": ["", "Google", "Google", ""], "paper_date": "2018-06-14", "metric": "28888"}, {"title": "Asynchronous Methods for Deep Reinforcement Learning@@@A3C LSTM hs", "authors": ["Volodymyr Mnih", "Adri\u00e0 Puigdom\u00e8nech Badia", "Mehdi Mirza", "Alex Graves", "Tim Harley", "Timothy P. Lillicrap", "David Silver", "Koray Kavukcuoglu"], "affiliations": ["Google", "Google", "Universit\u00e9 de Montr\u00e9al", "Google", "Google", "Google", "Google", "Google"], "paper_date": "2016-02-04", "metric": "23846.0"}, {"title": "Distributional Reinforcement Learning with Quantile Regression@@@QR-DQN-1", "authors": ["Will Dabney", "Mark Rowland", "Marc G. Bellemare", "R\u00e9mi Munos"], "affiliations": ["Google", "University of Cambridge", "Google", "Google"], "paper_date": "2017-10-27", "metric": "20972"}, {"title": "Asynchronous Methods for Deep Reinforcement Learning@@@A3C FF hs", "authors": ["Volodymyr Mnih", "Adri\u00e0 Puigdom\u00e8nech Badia", "Mehdi Mirza", "Alex Graves", "Tim Harley", "Timothy P. Lillicrap", "David Silver", "Koray Kavukcuoglu"], "affiliations": ["Google", "Google", "Universit\u00e9 de Montr\u00e9al", "Google", "Google", "Google", "Google", "Google"], "paper_date": "2016-02-04", "metric": "15730.5"}, {"title": "Dueling Network Architectures for Deep Reinforcement Learning@@@Prior+Duel noop", "authors": ["Ziyu Wang", "Tom Schaul", "Matteo Hessel", "H Van Hasselt", "Hado van Hasselt", "Marc Lanctot", "Nando de Freitas"], "affiliations": ["Google", "Google", "Google", "Google", "Google", "Google", "Google"], "paper_date": "2015-11-20", "metric": "15311.5"}, {"title": "Deep Reinforcement Learning with Double Q-learning@@@Prior+Duel hs", "authors": ["H Van Hasselt", "Hado van Hasselt", "Arthur Guez", "David Silver"], "affiliations": ["Google", "Google", "Google", "Google"], "paper_date": "2015-09-22", "metric": "8978.0"}, {"title": "Dueling Network Architectures for Deep Reinforcement Learning@@@Duel noop", "authors": ["Ziyu Wang", "Tom Schaul", "Matteo Hessel", "H Van Hasselt", "Hado van Hasselt", "Marc Lanctot", "Nando de Freitas"], "affiliations": ["Google", "Google", "Google", "Google", "Google", "Google", "Google"], "paper_date": "2015-11-20", "metric": "6427.3"}, {"title": "Dueling Network Architectures for Deep Reinforcement Learning@@@Duel hs", "authors": ["Ziyu Wang", "Tom Schaul", "Matteo Hessel", "H Van Hasselt", "Hado van Hasselt", "Marc Lanctot", "Nando de Freitas"], "affiliations": ["Google", "Google", "Google", "Google", "Google", "Google", "Google"], "paper_date": "2015-11-20", "metric": "5993.1"}, {"title": "Noisy Networks for Exploration@@@NoisyNet-Dueling", "authors": ["Meire Fortunato", "Mohammad Gheshlaghi Azar", "Bilal Piot", "Jacob Menick", "Ian Osband", "Alex Graves", "Vlad Mnih", "R\u00e9mi Munos", "Demis Hassabis", "Olivier Pietquin", "Charles Blundell", "Shane Legg"], "affiliations": ["", "", "", "", "", "", "", "", "", "", "", ""], "paper_date": "2017-06-30", "metric": "5909"}, {"title": "A Distributional Perspective on Reinforcement Learning@@@C51 noop", "authors": ["Marc G. Bellemare", "Will Dabney", "R\u00e9mi Munos"], "affiliations": ["Google", "Google", "Google"], "paper_date": "2017-07-21", "metric": "5747.0"}, {"title": "Prioritized Experience Replay@@@Prior hs", "authors": ["Tom Schaul", "John Quan", "Ioannis Antonoglou", "David Silver"], "affiliations": ["Google", "Google", "Google", "Google"], "paper_date": "2015-11-18", "metric": "3912.1"}, {"title": "Increasing the Action Gap: New Operators for Reinforcement Learning@@@Advantage Learning", "authors": ["Marc G. Bellemare", "Georg Ostrovski", "Arthur Guez", "Philip S. Thomas", "R\u00e9mi Munos"], "affiliations": ["Google", "Google", "Google", "Carnegie Mellon University", "Google"], "paper_date": "2015-12-15", "metric": "3460.79"}, {"title": "Increasing the Action Gap: New Operators for Reinforcement Learning@@@Persistent AL", "authors": ["Marc G. Bellemare", "Georg Ostrovski", "Arthur Guez", "Philip S. Thomas", "R\u00e9mi Munos"], "affiliations": ["Google", "Google", "Google", "Carnegie Mellon University", "Google"], "paper_date": "2015-12-15", "metric": "3277.59"}, {"title": "Self-Imitation Learning@@@A2C + SIL", "authors": ["Xin Wang", "Qiuyuan Huang", "Asli Celikyilmaz", "Jianfeng Gao", "Dinghan Shen", "Yuan-Fang Wang", "William Yang Wang", "Lei Zhang"], "affiliations": ["University of California, Santa Barbara", "Microsoft", "Microsoft", "Microsoft", "Duke University", "University of California, Santa Barbara", "University of California, Santa Barbara", "Microsoft"], "paper_date": "2018-06-14", "metric": "2951.7"}, {"title": "Deep Exploration via Bootstrapped DQN@@@Bootstrapped DQN", "authors": ["Ian Osband", "Charles Blundell", "Alexander Pritzel", "Benjamin Van Roy"], "affiliations": ["Stanford University", "Google", "Google", "Stanford University"], "paper_date": "2016-02-15", "metric": "2893"}, {"title": "Prioritized Experience Replay@@@Prior noop", "authors": ["Tom Schaul", "John Quan", "Ioannis Antonoglou", "David Silver"], "affiliations": ["Google", "Google", "Google", "Google"], "paper_date": "2015-11-18", "metric": "2865.8"}, {"title": "The Arcade Learning Environment: An Evaluation Platform for General Agents@@@UCT", "authors": ["Marc G. Bellemare", "Yavar Naddaf", "Joel Veness", "Michael Bowling"], "affiliations": ["University of Alberta", "", "University of Alberta", "University of Alberta"], "paper_date": "2012-07-19", "metric": "2718"}, {"title": "Deep Reinforcement Learning with Double Q-learning@@@DDQN (tuned) hs", "authors": ["H Van Hasselt", "Hado van Hasselt", "Arthur Guez", "David Silver"], "affiliations": ["Google", "Google", "Google", "Google"], "paper_date": "2015-09-22", "metric": "2628.7"}, {"title": "Learning values across many orders of magnitude@@@DDQN+Pop-Art noop", "authors": ["Hado van Hasselt", "H Van Hasselt", "Arthur Guez", "Matteo Hessel", "Volodymyr Mnih", "David Silver"], "affiliations": ["Google", "Google", "Google", "Google", "Google", "Google"], "paper_date": "2016-02-24", "metric": "2589.7"}, {"title": "Dueling Network Architectures for Deep Reinforcement Learning@@@DDQN (tuned) noop", "authors": ["Ziyu Wang", "Tom Schaul", "Matteo Hessel", "H Van Hasselt", "Hado van Hasselt", "Marc Lanctot", "Nando de Freitas"], "affiliations": ["Google", "Google", "Google", "Google", "Google", "Google", "Google"], "paper_date": "2015-11-20", "metric": "2525.5"}, {"title": "Asynchronous Methods for Deep Reinforcement Learning@@@A3C FF (1 day) hs", "authors": ["Volodymyr Mnih", "Adri\u00e0 Puigdom\u00e8nech Badia", "Mehdi Mirza", "Alex Graves", "Tim Harley", "Timothy P. Lillicrap", "David Silver", "Koray Kavukcuoglu"], "affiliations": ["Google", "Google", "Universit\u00e9 de Montr\u00e9al", "Google", "Google", "Google", "Google", "Google"], "paper_date": "2016-02-04", "metric": "2214.7"}, {"title": "Mastering Atari with Discrete World Models@@@DreamerV2", "authors": ["Danijar Hafner", "Timothy P. Lillicrap", "Mohammad Norouzi", "Jimmy Ba"], "affiliations": ["", "", "", ""], "paper_date": "2020-10-05", "metric": "2112"}, {"title": "Model-Free Episodic Control with State Aggregation@@@MFEC", "authors": ["Rafael Pinto"], "affiliations": ["Federal Institute of Rio Grande do Sul"], "paper_date": "2020-08-21", "metric": "1990"}, {"title": "@@@Nature DQN", "authors": [], "affiliations": [], "paper_date": null, "metric": "1976.0"}, {"title": "Deep Reinforcement Learning with Double Q-learning@@@DQN noop", "authors": ["H Van Hasselt", "Hado van Hasselt", "Arthur Guez", "David Silver"], "affiliations": ["Google", "Google", "Google", "Google"], "paper_date": "2015-09-22", "metric": "1692.3"}, {"title": "Deep Reinforcement Learning with Double Q-learning@@@DQN hs", "authors": ["H Van Hasselt", "Hado van Hasselt", "Arthur Guez", "David Silver"], "affiliations": ["Google", "Google", "Google", "Google"], "paper_date": "2015-09-22", "metric": "1293.8"}, {"title": "Policy Optimization With Penalized Point Probability Distance: An Alternative To Proximal Policy Optimization@@@POP3D", "authors": ["Xiangxiang Chu"], "affiliations": ["Xiaomi"], "paper_date": "2018-07-02", "metric": "1216.15"}, {"title": "Massively Parallel Methods for Deep Reinforcement Learning@@@Gorila", "authors": ["Arun Nair", "Praveen Srinivasan", "Sam Blackwell", "Cagdas Alcicek", "Rory Fearon", "Alessandro De Maria", "Vedavyas Panneershelvam", "Mustafa Suleyman", "Charles Beattie", "Stig Petersen", "Koray Kavukcuoglu", "David Silver"], "affiliations": ["Google", "", "", "", "", "", "", "", "", "", "", ""], "paper_date": "2015-07-15", "metric": "1183.3"}, {"title": "Mean Actor Critic@@@MAC", "authors": ["Kamil Ciosek", "Quan Vuong", "Robert Loftin", "Katja Hofmann"], "affiliations": ["Microsoft", "University of California, San Diego", "Microsoft", "Microsoft"], "paper_date": "2017-09-01", "metric": "1173.1"}, {"title": "Playing Atari with Deep Reinforcement Learning@@@DQN Best", "authors": ["Volodymyr Mnih", "Koray Kavukcuoglu", "David Silver", "Alex Graves", "Ioannis Antonoglou", "Daan Wierstra", "Martin Riedmiller"], "affiliations": ["", "", "", "", "", "", ""], "paper_date": "2013-12-19", "metric": "1075"}, {"title": "Evolving simple programs for playing Atari games@@@CGP", "authors": ["Dennis G. Wilson", "Sylvain Cussat-Blanc", "Herv\u00e9 Luga", "Julian F. Miller"], "affiliations": ["University of Toulouse", "University of Toulouse", "University of Toulouse", "University of York"], "paper_date": "2018-06-14", "metric": "1001"}, {"title": "Playing Atari with Six Neurons@@@IDVQ + DRSC + XNES", "authors": ["Giuseppe Cuccu", "Julian Togelius", "Philippe Cudr\u00e9-Mauroux"], "affiliations": ["University of Fribourg", "New York University", "University of Fribourg"], "paper_date": "2018-06-04", "metric": "830"}, {"title": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning@@@ES FF (1 hour) noop", "authors": ["Tim Salimans", "Jonathan Ho", "Xi Chen", "Szymon Sidor", "Ilya Sutskever"], "affiliations": ["", "", "", "", ""], "paper_date": "2017-03-10", "metric": "678.5"}, {"title": "Distributed Deep Reinforcement Learning: Learn how to play Atari games in 21 minutes@@@DDRL A3C", "authors": ["Igor Adamski", "Robert Adamski", "Tomasz Grel", "Adam J\u0119drych", "Kamil Kaczmarek", "Henryk Michalewski"], "affiliations": ["", "Intel", "", "", "", "Polish Academy of Sciences"], "paper_date": "2018-01-09", "metric": "650"}, {"title": "Deep Attention Recurrent Q-Network@@@DARQN soft", "authors": ["Ivan Sorokin", "Alexey Seleznev", "Mikhail Pavlov", "Aleksandr Fedorov", "Anastasiia Ignateva"], "affiliations": ["", "", "", "", ""], "paper_date": "2015-12-05", "metric": "650"}, {"title": "@@@SARSA", "authors": [], "affiliations": [], "paper_date": null, "metric": "267.9"}, {"title": "The Arcade Learning Environment: An Evaluation Platform for General Agents@@@Best Learner", "authors": ["Marc G. Bellemare", "Yavar Naddaf", "Joel Veness", "Michael Bowling"], "affiliations": ["University of Alberta", "", "University of Alberta", "University of Alberta"], "paper_date": "2012-07-19", "metric": "250.1"}, {"title": "Soft Actor-Critic for Discrete Action Settings@@@SAC", "authors": ["Petros Christodoulou"], "affiliations": ["Imperial College London"], "paper_date": "2019-10-16", "metric": "160.8"}, {"title": "Rainbow: Combining Improvements in Deep Reinforcement Learning@@@Rainbow", "authors": ["Matteo Hessel", "Joseph Modayil", "Hado van Hasselt", "H Van Hasselt", "Tom Schaul", "Georg Ostrovski", "Will Dabney", "Dan Horgan", "Bilal Piot", "David Silver", "Mohammad Gheshlaghi Azar"], "affiliations": ["Google", "University of Alberta", "Google", "Google", "Google", "Google", "Google", "Google", "university of lille", "Google", "Northwestern University"], "paper_date": "2017-10-06", "metric": "12,629.0"}]