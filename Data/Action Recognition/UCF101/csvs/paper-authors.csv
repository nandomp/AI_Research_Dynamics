"title","authors","affiliations","paper_date","metric","year"
"Late Temporal Modeling in 3D CNN Architectures with BERT for Action Recognition@@@R2+1D-BERT","M. Esat Kalfaoglu","Middle East Technical University",2020-08-03,"98.69",2020
"Late Temporal Modeling in 3D CNN Architectures with BERT for Action Recognition@@@R2+1D-BERT","Sinan Kalkan","Middle East Technical University",2020-08-03,"98.69",2020
"Late Temporal Modeling in 3D CNN Architectures with BERT for Action Recognition@@@R2+1D-BERT","A. Aydin Alatan","Middle East Technical University",2020-08-03,"98.69",2020
"Omni-sourced Webly-supervised Learning for Video Recognition@@@OmniSource (SlowOnly-8x8-R101-RGB + I3D-Flow)","Haodong Duan","",2020-03-29,"98.6",2020
"Omni-sourced Webly-supervised Learning for Video Recognition@@@OmniSource (SlowOnly-8x8-R101-RGB + I3D-Flow)","Yue Zhao","",2020-03-29,"98.6",2020
"Omni-sourced Webly-supervised Learning for Video Recognition@@@OmniSource (SlowOnly-8x8-R101-RGB + I3D-Flow)","Yuanjun Xiong","",2020-03-29,"98.6",2020
"Omni-sourced Webly-supervised Learning for Video Recognition@@@OmniSource (SlowOnly-8x8-R101-RGB + I3D-Flow)","Wentao Liu","",2020-03-29,"98.6",2020
"Omni-sourced Webly-supervised Learning for Video Recognition@@@OmniSource (SlowOnly-8x8-R101-RGB + I3D-Flow)","Dahua Lin","",2020-03-29,"98.6",2020
"Learning Spatio-Temporal Representation with Local and Global Diffusion@@@LGD-3D Two-stream","Zhaofan Qiu","University of Science and Technology of China",2019-06-13,"98.2",2019
"Learning Spatio-Temporal Representation with Local and Global Diffusion@@@LGD-3D Two-stream","Ting Yao","",2019-06-13,"98.2",2019
"Learning Spatio-Temporal Representation with Local and Global Diffusion@@@LGD-3D Two-stream","Chong-Wah Ngo","City University of Hong Kong",2019-06-13,"98.2",2019
"Learning Spatio-Temporal Representation with Local and Global Diffusion@@@LGD-3D Two-stream","Xinmei Tian","",2019-06-13,"98.2",2019
"Learning Spatio-Temporal Representation with Local and Global Diffusion@@@LGD-3D Two-stream","Tao Mei","",2019-06-13,"98.2",2019
"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset@@@Two-stream I3D (on pre-trained)","Joao Carreira","Google",2017-05-22,"98.0",2017
"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset@@@Two-stream I3D (on pre-trained)","Andrew Zisserman","University of Oxford",2017-05-22,"98.0",2017
"MARS: Motion-Augmented RGB Stream for Action Recognition@@@MARS+RGB+Flow (64 frames, Kinetics pretrained)","Nieves Crasto","",2019-06-01,"97.8",2019
"MARS: Motion-Augmented RGB Stream for Action Recognition@@@MARS+RGB+Flow (64 frames, Kinetics pretrained)","Philippe Weinzaepfel","",2019-06-01,"97.8",2019
"MARS: Motion-Augmented RGB Stream for Action Recognition@@@MARS+RGB+Flow (64 frames, Kinetics pretrained)","Karteek Alahari","",2019-06-01,"97.8",2019
"MARS: Motion-Augmented RGB Stream for Action Recognition@@@MARS+RGB+Flow (64 frames, Kinetics pretrained)","Cordelia Schmid","",2019-06-01,"97.8",2019
"Large Scale Holistic Video Understanding@@@HATNet (32 frames)","Ali Diba","",2019-04-25,"97.8",2019
"Large Scale Holistic Video Understanding@@@HATNet (32 frames)","Mohsen Fayyaz","",2019-04-25,"97.8",2019
"Large Scale Holistic Video Understanding@@@HATNet (32 frames)","Vivek Sharma","",2019-04-25,"97.8",2019
"Large Scale Holistic Video Understanding@@@HATNet (32 frames)","Manohar Paluri","",2019-04-25,"97.8",2019
"Large Scale Holistic Video Understanding@@@HATNet (32 frames)","Jürgen Gall","ETH Zurich",2019-04-25,"97.8",2019
"Large Scale Holistic Video Understanding@@@HATNet (32 frames)","Rainer Stiefelhagen","",2019-04-25,"97.8",2019
"Large Scale Holistic Video Understanding@@@HATNet (32 frames)","Luc Van Gool","",2019-04-25,"97.8",2019
"Cooperative Cross-Stream Network for Discriminative Action Representation@@@CCS + TSN (ImageNet+Kinetics pretrained)","Jingran Zhang","",2019-08-27,"97.4",2019
"Cooperative Cross-Stream Network for Discriminative Action Representation@@@CCS + TSN (ImageNet+Kinetics pretrained)","Fumin Shen","",2019-08-27,"97.4",2019
"Cooperative Cross-Stream Network for Discriminative Action Representation@@@CCS + TSN (ImageNet+Kinetics pretrained)","Xing Xu","University of Electronic Science and Technology of China",2019-08-27,"97.4",2019
"Cooperative Cross-Stream Network for Discriminative Action Representation@@@CCS + TSN (ImageNet+Kinetics pretrained)","Heng Tao Shen","",2019-08-27,"97.4",2019
"Contextual Action Cues from Camera Sensor for Multi-Stream Action Recognition@@@Multi-stream I3D ","Jongkwang Hong","Yonsei University",2019-03-20,"97.2",2019
"Contextual Action Cues from Camera Sensor for Multi-Stream Action Recognition@@@Multi-stream I3D ","Bora Cho","Yonsei University",2019-03-20,"97.2",2019
"Contextual Action Cues from Camera Sensor for Multi-Stream Action Recognition@@@Multi-stream I3D ","Yong Won Hong","Yonsei University",2019-03-20,"97.2",2019
"Contextual Action Cues from Camera Sensor for Multi-Stream Action Recognition@@@Multi-stream I3D ","Hyeran Byun","Yonsei University",2019-03-20,"97.2",2019
"Hidden Two-Stream Convolutional Networks for Action Recognition@@@Hidden Two-Stream","Yi Zhu","University of California, Merced",2017-04-02,"97.1",2017
"Hidden Two-Stream Convolutional Networks for Action Recognition@@@Hidden Two-Stream","Zhenzhong Lan","Carnegie Mellon University",2017-04-02,"97.1",2017
"Hidden Two-Stream Convolutional Networks for Action Recognition@@@Hidden Two-Stream","Shawn Newsam","University of California, Merced",2017-04-02,"97.1",2017
"Hidden Two-Stream Convolutional Networks for Action Recognition@@@Hidden Two-Stream","Alexander G. Hauptmann","Carnegie Mellon University",2017-04-02,"97.1",2017
"Two-Stream Video Classification with Cross-Modality Attention@@@CMA iter1-S","Lu Chi","Peking University",2019-08-01,"96.5",2019
"Two-Stream Video Classification with Cross-Modality Attention@@@CMA iter1-S","Guiyu Tian","Peking University",2019-08-01,"96.5",2019
"Two-Stream Video Classification with Cross-Modality Attention@@@CMA iter1-S","Yadong Mu","Peking University",2019-08-01,"96.5",2019
"Two-Stream Video Classification with Cross-Modality Attention@@@CMA iter1-S","Qi Tian","Huawei",2019-08-01,"96.5",2019
"STM: SpatioTemporal and Motion Encoding for Action Recognition@@@STM (ImageNet+Kinetics pretrain)","Boyuan Jiang","Zhejiang University",2019-08-07,"96.2",2019
"STM: SpatioTemporal and Motion Encoding for Action Recognition@@@STM (ImageNet+Kinetics pretrain)","Mengmeng Wang","SenseTime",2019-08-07,"96.2",2019
"STM: SpatioTemporal and Motion Encoding for Action Recognition@@@STM (ImageNet+Kinetics pretrain)","Weihao Gan","SenseTime",2019-08-07,"96.2",2019
"STM: SpatioTemporal and Motion Encoding for Action Recognition@@@STM (ImageNet+Kinetics pretrain)","Wei Wu","SenseTime",2019-08-07,"96.2",2019
"STM: SpatioTemporal and Motion Encoding for Action Recognition@@@STM (ImageNet+Kinetics pretrain)","Junjie Yan","SenseTime",2019-08-07,"96.2",2019
"Multi-Fiber Networks for Video Recognition@@@MF-Net, RGB only (ImageNet+Kinetics pretrained)","Yunpeng Chen","National University of Singapore",2018-07-30,"96.0",2018
"Multi-Fiber Networks for Video Recognition@@@MF-Net, RGB only (ImageNet+Kinetics pretrained)","Yannis Kalantidis","Facebook",2018-07-30,"96.0",2018
"Multi-Fiber Networks for Video Recognition@@@MF-Net, RGB only (ImageNet+Kinetics pretrained)","Jianshu Li","National University of Singapore",2018-07-30,"96.0",2018
"Multi-Fiber Networks for Video Recognition@@@MF-Net, RGB only (ImageNet+Kinetics pretrained)","Shuicheng Yan","National University of Singapore",2018-07-30,"96.0",2018
"Multi-Fiber Networks for Video Recognition@@@MF-Net, RGB only (ImageNet+Kinetics pretrained)","Jiashi Feng","National University of Singapore",2018-07-30,"96.0",2018
"Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition@@@Optical Flow Guided Feature","Shuyang Sun","University of Sydney",2017-11-29,"96",2017
"Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition@@@Optical Flow Guided Feature","Zhanghui Kuang","",2017-11-29,"96",2017
"Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition@@@Optical Flow Guided Feature","Lu Sheng","The Chinese University of Hong Kong",2017-11-29,"96",2017
"Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition@@@Optical Flow Guided Feature","Wanli Ouyang","University of Sydney",2017-11-29,"96",2017
"Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition@@@Optical Flow Guided Feature","Wei Zhang","SenseTime",2017-11-29,"96",2017
"MARS: Motion-Augmented RGB Stream for Action Recognition@@@MARS+RGB+Flow (16 frames)","Nieves Crasto","",2019-06-01,"95.8",2019
"MARS: Motion-Augmented RGB Stream for Action Recognition@@@MARS+RGB+Flow (16 frames)","Philippe Weinzaepfel","",2019-06-01,"95.8",2019
"MARS: Motion-Augmented RGB Stream for Action Recognition@@@MARS+RGB+Flow (16 frames)","Karteek Alahari","",2019-06-01,"95.8",2019
"MARS: Motion-Augmented RGB Stream for Action Recognition@@@MARS+RGB+Flow (16 frames)","Cordelia Schmid","",2019-06-01,"95.8",2019
"Attention Distillation for Learning Video Representations@@@Prob-Distill","Miao Liu","Georgia Institute of Technology",2019-04-05,"95.7",2019
"Attention Distillation for Learning Video Representations@@@Prob-Distill","Xin Chen","",2019-04-05,"95.7",2019
"Attention Distillation for Learning Video Representations@@@Prob-Distill","Yun Zhang","Georgia Institute of Technology",2019-04-05,"95.7",2019
"Attention Distillation for Learning Video Representations@@@Prob-Distill","Yin Li","University of Wisconsin-Madison",2019-04-05,"95.7",2019
"Attention Distillation for Learning Video Representations@@@Prob-Distill","James M. Rehg","Georgia Institute of Technology",2019-04-05,"95.7",2019
"Learning spatio-temporal representations with temporal squeeze pooling@@@TesNet (ImageNet pretrained)","Guoxi Huang","University of York",2020-02-11,"95.2",2020
"Learning spatio-temporal representations with temporal squeeze pooling@@@TesNet (ImageNet pretrained)","Adrian G. Bors","University of York",2020-02-11,"95.2",2020
"I3D-LSTM: A New Model for Human Action Recognition@@@I3D-LSTM","Xianyuan Wang","",2019-08-09,"95.1",2019
"I3D-LSTM: A New Model for Human Action Recognition@@@I3D-LSTM","Zhenjiang Miao","",2019-08-09,"95.1",2019
"I3D-LSTM: A New Model for Human Action Recognition@@@I3D-LSTM","Ruyi Zhang","",2019-08-09,"95.1",2019
"I3D-LSTM: A New Model for Human Action Recognition@@@I3D-LSTM","Shanshan Hao","",2019-08-09,"95.1",2019
"Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?@@@ResNeXt-101 (64f)","Kensho Hara","National Institute of Advanced Industrial Science and Technology",2017-11-27,"94.5",2017
"Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?@@@ResNeXt-101 (64f)","Hirokatsu Kataoka","National Institute of Advanced Industrial Science and Technology",2017-11-27,"94.5",2017
"Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?@@@ResNeXt-101 (64f)","Yutaka Satoh","National Institute of Advanced Industrial Science and Technology",2017-11-27,"94.5",2017
"R-STAN: Residual Spatial-Temporal Attention Network for Action Recognition@@@R-STAN-101","Quanle Liu","Jilin University",2019-06-19,"94.5",2019
"R-STAN: Residual Spatial-Temporal Attention Network for Action Recognition@@@R-STAN-101","Xiangjiu Che","Jilin University",2019-06-19,"94.5",2019
"R-STAN: Residual Spatial-Temporal Attention Network for Action Recognition@@@R-STAN-101","Mei Bie","Jilin University",2019-06-19,"94.5",2019
"Temporal-Spatial Mapping for Action Recognition@@@TSN+TSM","Xiaolin Song","Tianjin University",2018-09-11,"94.3",2018
"Temporal-Spatial Mapping for Action Recognition@@@TSN+TSM","Cuiling Lan","Microsoft",2018-09-11,"94.3",2018
"Temporal-Spatial Mapping for Action Recognition@@@TSN+TSM","Wenjun Zeng","Microsoft",2018-09-11,"94.3",2018
"Temporal-Spatial Mapping for Action Recognition@@@TSN+TSM","Junliang Xing","Chinese Academy of Sciences",2018-09-11,"94.3",2018
"Temporal-Spatial Mapping for Action Recognition@@@TSN+TSM","Xiaoyan Sun","Microsoft",2018-09-11,"94.3",2018
"Temporal-Spatial Mapping for Action Recognition@@@TSN+TSM","Jingyu Yang","Tianjin University",2018-09-11,"94.3",2018
"TS-LSTM and Temporal-Inception: Exploiting Spatiotemporal Dynamics for Activity Recognition@@@TS-LSTM","Chih-Yao Ma","Georgia Institute of Technology",2017-03-30,"94.1",2017
"TS-LSTM and Temporal-Inception: Exploiting Spatiotemporal Dynamics for Activity Recognition@@@TS-LSTM","Min-Hung Chen","Georgia Institute of Technology",2017-03-30,"94.1",2017
"TS-LSTM and Temporal-Inception: Exploiting Spatiotemporal Dynamics for Activity Recognition@@@TS-LSTM","Zsolt Kira","Georgia Tech Research Institute",2017-03-30,"94.1",2017
"TS-LSTM and Temporal-Inception: Exploiting Spatiotemporal Dynamics for Activity Recognition@@@TS-LSTM","Ghassan AlRegib","Georgia Institute of Technology",2017-03-30,"94.1",2017
"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset@@@Two-stream I3D","Joao Carreira","Google",2017-05-22,"93.4",2017
"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset@@@Two-stream I3D","Andrew Zisserman","University of Oxford",2017-05-22,"93.4",2017
"Convolutional Two-Stream Network Fusion for Video Action Recognition@@@S:VGG-16, T:VGG-16","Christoph Feichtenhofer","Graz University of Technology",2016-04-22,"92.5",2016
"Convolutional Two-Stream Network Fusion for Video Action Recognition@@@S:VGG-16, T:VGG-16","Axel Pinz","Graz University of Technology",2016-04-22,"92.5",2016
"Convolutional Two-Stream Network Fusion for Video Action Recognition@@@S:VGG-16, T:VGG-16","Andrew Zisserman","University of Oxford",2016-04-22,"92.5",2016
"Dance with Flow: Two-in-One Stream Action Detection@@@two-in-one two stream","Jiaojiao Zhao","University of Amsterdam",2019-04-01,"92",2019
"Dance with Flow: Two-in-One Stream Action Detection@@@two-in-one two stream","Cees G. M. Snoek","University of Amsterdam",2019-04-01,"92",2019
"Long-term Temporal Convolutions for Action Recognition@@@LTC","Gül Varol","École Normale Supérieure",2016-04-15,"91.7",2016
"Long-term Temporal Convolutions for Action Recognition@@@LTC","Ivan Laptev","École Normale Supérieure",2016-04-15,"91.7",2016
"Long-term Temporal Convolutions for Action Recognition@@@LTC","Cordelia Schmid","French Institute for Research in Computer Science and Automation",2016-04-15,"91.7",2016
"R-STAN: Residual Spatial-Temporal Attention Network for Action Recognition@@@R-STAN-50","Quanle Liu","Jilin University",2019-06-19,"91.5",2019
"R-STAN: Residual Spatial-Temporal Attention Network for Action Recognition@@@R-STAN-50","Xiangjiu Che","Jilin University",2019-06-19,"91.5",2019
"R-STAN: Residual Spatial-Temporal Attention Network for Action Recognition@@@R-STAN-50","Mei Bie","Jilin University",2019-06-19,"91.5",2019
"Towards Good Practices for Very Deep Two-Stream ConvNets@@@Very deep two-stream ConvNet","Limin Wang","",2015-07-08,"91.4",2015
"Towards Good Practices for Very Deep Two-Stream ConvNets@@@Very deep two-stream ConvNet","Yuanjun Xiong","",2015-07-08,"91.4",2015
"Towards Good Practices for Very Deep Two-Stream ConvNets@@@Very deep two-stream ConvNet","Zhe Wang","",2015-07-08,"91.4",2015
"Towards Good Practices for Very Deep Two-Stream ConvNets@@@Very deep two-stream ConvNet","Yu Qiao","Chinese Academy of Sciences",2015-07-08,"91.4",2015
"Multi-region two-stream R-CNN for action detection@@@MR Two-Sream R-CNN","Xiaojiang Peng","",2016-09-17,"91.1",2016
"Multi-region two-stream R-CNN for action detection@@@MR Two-Sream R-CNN","Cordelia Schmid","",2016-09-17,"91.1",2016
"Beyond Short Snippets: Deep Networks for Video Classification@@@Two-stream+LSTM","Joe Yue-Hei Ng","University of Maryland, College Park",2015-03-31,"88.6",2015
"Beyond Short Snippets: Deep Networks for Video Classification@@@Two-stream+LSTM","Matthew Hausknecht","University of Texas at Austin",2015-03-31,"88.6",2015
"Beyond Short Snippets: Deep Networks for Video Classification@@@Two-stream+LSTM","Sudheendra Vijayanarasimhan","Google",2015-03-31,"88.6",2015
"Beyond Short Snippets: Deep Networks for Video Classification@@@Two-stream+LSTM","Oriol Vinyals","Google",2015-03-31,"88.6",2015
"Beyond Short Snippets: Deep Networks for Video Classification@@@Two-stream+LSTM","Rajat Monga","Google",2015-03-31,"88.6",2015
"Beyond Short Snippets: Deep Networks for Video Classification@@@Two-stream+LSTM","George Toderici","Google",2015-03-31,"88.6",2015
"Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks@@@P3D","Zhaofan Qiu","University of Science and Technology of China",2017-11-28,"88.6",2017
"Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks@@@P3D","Ting Yao","Microsoft",2017-11-28,"88.6",2017
"Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks@@@P3D","Tao Mei","Microsoft",2017-11-28,"88.6",2017
"Two-Stream Convolutional Networks for Action Recognition in Videos@@@Two-stream","Karen Simonyan","University of Oxford",2014-06-09,"88.0",2014
"Two-Stream Convolutional Networks for Action Recognition in Videos@@@Two-stream","Andrew Zisserman","University of Oxford",2014-06-09,"88.0",2014
"Bag of Visual Words and Fusion Methods for Action Recognition: Comprehensive Study and Good Practice@@@iDT+HSV","Xiaojiang Peng","",2014-05-18,"87.9",2014
"Bag of Visual Words and Fusion Methods for Action Recognition: Comprehensive Study and Good Practice@@@iDT+HSV","Limin Wang","",2014-05-18,"87.9",2014
"Bag of Visual Words and Fusion Methods for Action Recognition: Comprehensive Study and Good Practice@@@iDT+HSV","Xingxing Wang","",2014-05-18,"87.9",2014
"Bag of Visual Words and Fusion Methods for Action Recognition: Comprehensive Study and Good Practice@@@iDT+HSV","Yu Qiao","",2014-05-18,"87.9",2014
"DistInit: Learning Video Representations Without a Single Labeled Video@@@R(2+1)D-18 (DistInit pretraining)","Rohit Girdhar","Carnegie Mellon University",2019-01-26,"85.8",2019
"DistInit: Learning Video Representations Without a Single Labeled Video@@@R(2+1)D-18 (DistInit pretraining)","Du Tran","Facebook",2019-01-26,"85.8",2019
"DistInit: Learning Video Representations Without a Single Labeled Video@@@R(2+1)D-18 (DistInit pretraining)","Lorenzo Torresani","Facebook",2019-01-26,"85.8",2019
"DistInit: Learning Video Representations Without a Single Labeled Video@@@R(2+1)D-18 (DistInit pretraining)","Deva Ramanan","Carnegie Mellon University",2019-01-26,"85.8",2019
"Resource Efficient 3D Convolutional Neural Networks@@@3D-SqueezeNet","Okan Köpüklü","Technische Universität München",2019-04-04,"74.94",2019
"Resource Efficient 3D Convolutional Neural Networks@@@3D-SqueezeNet","Neslihan Kose","Intel",2019-04-04,"74.94",2019
"Resource Efficient 3D Convolutional Neural Networks@@@3D-SqueezeNet","Ahmet Gunduz","Technische Universität München",2019-04-04,"74.94",2019
"Resource Efficient 3D Convolutional Neural Networks@@@3D-SqueezeNet","Gerhard Rigoll","Technische Universität München",2019-04-04,"74.94",2019
"Large-Scale Video Classification with Convolutional Neural Networks@@@Slow Fusion + Finetune top 3 layers","Andrej Karpathy","Stanford University",2014-06-23,"65.4",2014
"Large-Scale Video Classification with Convolutional Neural Networks@@@Slow Fusion + Finetune top 3 layers","George Toderici","Stanford University",2014-06-23,"65.4",2014
"Large-Scale Video Classification with Convolutional Neural Networks@@@Slow Fusion + Finetune top 3 layers","Sanketh Shetty","Stanford University",2014-06-23,"65.4",2014
"Large-Scale Video Classification with Convolutional Neural Networks@@@Slow Fusion + Finetune top 3 layers","Thomas Leung","Stanford University",2014-06-23,"65.4",2014
"Large-Scale Video Classification with Convolutional Neural Networks@@@Slow Fusion + Finetune top 3 layers","Rahul Sukthankar","Stanford University",2014-06-23,"65.4",2014
"Large-Scale Video Classification with Convolutional Neural Networks@@@Slow Fusion + Finetune top 3 layers","Li Fei-Fei","Stanford University",2014-06-23,"65.4",2014
"MLGCN: Multi-Laplacian Graph Convolutional Networks for Human Action Recognition@@@MLGCN","Ahmed Mazari","",2019-09-11,"63.27",2019
"MLGCN: Multi-Laplacian Graph Convolutional Networks for Human Action Recognition@@@MLGCN","Hichem Sahbi","",2019-09-11,"63.27",2019
"Self-supervised Spatio-temporal Representation Learning for Videos by Predicting Motion and Appearance Statistics@@@Pretrained on Kinetics","Jiangliu Wang","The Chinese University of Hong Kong",2019-04-07,"61.2",2019
"Self-supervised Spatio-temporal Representation Learning for Videos by Predicting Motion and Appearance Statistics@@@Pretrained on Kinetics","Jianbo Jiao","University of Oxford",2019-04-07,"61.2",2019
"Self-supervised Spatio-temporal Representation Learning for Videos by Predicting Motion and Appearance Statistics@@@Pretrained on Kinetics","Linchao Bao","Tencent",2019-04-07,"61.2",2019
"Self-supervised Spatio-temporal Representation Learning for Videos by Predicting Motion and Appearance Statistics@@@Pretrained on Kinetics","Shengfeng He","South China University of Technology",2019-04-07,"61.2",2019
"Self-supervised Spatio-temporal Representation Learning for Videos by Predicting Motion and Appearance Statistics@@@Pretrained on Kinetics","Yunhui Liu","The Chinese University of Hong Kong",2019-04-07,"61.2",2019
"Self-supervised Spatio-temporal Representation Learning for Videos by Predicting Motion and Appearance Statistics@@@Pretrained on Kinetics","Yun-Hui Liu","The Chinese University of Hong Kong",2019-04-07,"61.2",2019
"Self-supervised Spatio-temporal Representation Learning for Videos by Predicting Motion and Appearance Statistics@@@Pretrained on Kinetics","Wei Liu","Tencent",2019-04-07,"61.2",2019
"Resource Efficient 3D Convolutional Neural Networks@@@3D-ShuffleNetV2 0.25x","Okan Köpüklü","Technische Universität München",2019-04-04,"56.52",2019
"Resource Efficient 3D Convolutional Neural Networks@@@3D-ShuffleNetV2 0.25x","Neslihan Kose","Intel",2019-04-04,"56.52",2019
"Resource Efficient 3D Convolutional Neural Networks@@@3D-ShuffleNetV2 0.25x","Ahmet Gunduz","Technische Universität München",2019-04-04,"56.52",2019
"Resource Efficient 3D Convolutional Neural Networks@@@3D-ShuffleNetV2 0.25x","Gerhard Rigoll","Technische Universität München",2019-04-04,"56.52",2019
"Resource Efficient 3D Convolutional Neural Networks@@@3D-MobileNetV2 0.2x","Okan Köpüklü","Technische Universität München",2019-04-04,"55.56",2019
"Resource Efficient 3D Convolutional Neural Networks@@@3D-MobileNetV2 0.2x","Neslihan Kose","Intel",2019-04-04,"55.56",2019
"Resource Efficient 3D Convolutional Neural Networks@@@3D-MobileNetV2 0.2x","Ahmet Gunduz","Technische Universität München",2019-04-04,"55.56",2019
"Resource Efficient 3D Convolutional Neural Networks@@@3D-MobileNetV2 0.2x","Gerhard Rigoll","Technische Universität München",2019-04-04,"55.56",2019
"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild@@@Baseline UCF101","Khurram Soomro","",2012-12-03,"43.9",2012
"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild@@@Baseline UCF101","Amir Roshan Zamir","",2012-12-03,"43.9",2012
"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild@@@Baseline UCF101","Mubarak Shah","",2012-12-03,"43.9",2012
"Towards Universal Representation for Unseen Action Recognition@@@CD-UAR","Yi Zhu","University of California, Merced",2018-03-22,"42.5",2018
"Towards Universal Representation for Unseen Action Recognition@@@CD-UAR","Yang Long","Newcastle University",2018-03-22,"42.5",2018
"Towards Universal Representation for Unseen Action Recognition@@@CD-UAR","Yu Guan","Newcastle University",2018-03-22,"42.5",2018
"Towards Universal Representation for Unseen Action Recognition@@@CD-UAR","Shawn Newsam","University of California, Merced",2018-03-22,"42.5",2018
"Towards Universal Representation for Unseen Action Recognition@@@CD-UAR","Ling Shao","University of East Anglia",2018-03-22,"42.5",2018
"PoTion: Pose MoTion Representation for Action Recognition@@@I3D + PoTion","Vasileios Choutas","",2018-06-01,"29.3",2018
"PoTion: Pose MoTion Representation for Action Recognition@@@I3D + PoTion","Philippe Weinzaepfel","",2018-06-01,"29.3",2018
"PoTion: Pose MoTion Representation for Action Recognition@@@I3D + PoTion","Jerome Revaud","",2018-06-01,"29.3",2018
"PoTion: Pose MoTion Representation for Action Recognition@@@I3D + PoTion","Cordelia Schmid","French Institute for Research in Computer Science and Automation",2018-06-01,"29.3",2018
