[{"title": "Late Temporal Modeling in 3D CNN Architectures with BERT for Action Recognition@@@R2+1D-BERT", "authors": ["M. Esat Kalfaoglu", "Sinan Kalkan", "A. Aydin Alatan"], "affiliations": ["Middle East Technical University", "Middle East Technical University", "Middle East Technical University"], "paper_date": "2020-08-03", "metric": "85.10"}, {"title": "Omni-sourced Webly-supervised Learning for Video Recognition@@@OmniSource (SlowOnly-8x8-R101-RGB + I3D Flow)", "authors": ["Haodong Duan", "Yue Zhao", "Yuanjun Xiong", "Wentao Liu", "Dahua Lin"], "affiliations": ["", "", "", "", ""], "paper_date": "2020-03-29", "metric": "83.8"}, {"title": "@@@BubbleNET", "authors": [], "affiliations": [], "paper_date": null, "metric": "82.60"}, {"title": "Hallucinating IDT Descriptors and I3D Optical Flow Features for Action Recognition with CNNs@@@HAF+BoW/FV halluc", "authors": ["Lei Wang", "Piotr Koniusz", "Du Q. Huynh"], "affiliations": ["University of Western Australia", "Commonwealth Scientific and Industrial Research Organisation", "University of Western Australia"], "paper_date": "2019-06-13", "metric": "82.48"}, {"title": "Cooperative Cross-Stream Network for Discriminative Action Representation@@@CCS + TSN (ImageNet+Kinetics pretrained)", "authors": ["Jingran Zhang", "Fumin Shen", "Xing Xu", "Heng Tao Shen"], "affiliations": ["", "", "University of Electronic Science and Technology of China", ""], "paper_date": "2019-08-27", "metric": "81.9"}, {"title": "Representation Flow for Action Recognition@@@RepFlow-50", "authors": ["AJ Piergiovanni", "Michael S. Ryoo"], "affiliations": ["Indiana University", "Indiana University"], "paper_date": "2018-10-02", "metric": "81.1"}, {"title": "Contextual Action Cues from Camera Sensor for Multi-Stream Action Recognition@@@Multi-stream I3D ", "authors": ["Jongkwang Hong", "Bora Cho", "Yong Won Hong", "Hyeran Byun"], "affiliations": ["Yonsei University", "Yonsei University", "Yonsei University", "Yonsei University"], "paper_date": "2019-03-20", "metric": "80.92"}, {"title": "MARS: Motion-Augmented RGB Stream for Action Recognition@@@MARS+RGB+FLow (64 frames, Kinetics pretrained)", "authors": ["Nieves Crasto", "Philippe Weinzaepfel", "Karteek Alahari", "Cordelia Schmid"], "affiliations": ["", "", "", ""], "paper_date": "2019-06-01", "metric": "80.9"}, {"title": "Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset@@@Two-stream I3D", "authors": ["Joao Carreira", "Andrew Zisserman"], "affiliations": ["Google", "University of Oxford"], "paper_date": "2017-05-22", "metric": "80.9"}, {"title": "Learning Spatio-Temporal Representation with Local and Global Diffusion@@@LGD-3D Two-stream", "authors": ["Zhaofan Qiu", "Ting Yao", "Chong-Wah Ngo", "Xinmei Tian", "Tao Mei"], "affiliations": ["University of Science and Technology of China", "", "City University of Hong Kong", "", ""], "paper_date": "2019-06-13", "metric": "80.5"}, {"title": "Hidden Two-Stream Convolutional Networks for Action Recognition@@@Hidden Two-Stream", "authors": ["Yi Zhu", "Zhenzhong Lan", "Shawn Newsam", "Alexander G. Hauptmann"], "affiliations": ["University of California, Merced", "Carnegie Mellon University", "University of California, Merced", "Carnegie Mellon University"], "paper_date": "2017-04-02", "metric": "78.7"}, {"title": "MotionSqueeze: Neural Motion Feature Learning for Video Understanding@@@MSNet-R50 (16 frames, ImageNet pretrained)", "authors": ["Heeseung Kwon", "Manjin Kim", "Suha Kwak", "Minsu Cho"], "affiliations": ["", "", "", ""], "paper_date": "2020-07-20", "metric": "77.4"}, {"title": "Large Scale Holistic Video Understanding@@@HATNet (32 frames)", "authors": ["Ali Diba", "Mohsen Fayyaz", "Vivek Sharma", "Manohar Paluri", "J\u00fcrgen Gall", "Rainer Stiefelhagen", "Luc Van Gool"], "affiliations": ["", "", "", "", "ETH Zurich", "", ""], "paper_date": "2019-04-25", "metric": "76.5"}, {"title": "FASTER Recurrent Networks for Efficient Video Classification@@@FASTER32 (Kinetics pretrain)", "authors": ["Linchao Zhu", "Du Tran", "Laura Sevilla-Lara", "Yi Yang", "Matt Feiszli", "Heng Wang"], "affiliations": ["University of Technology, Sydney", "Facebook", "Facebook", "University of Technology, Sydney", "Facebook", "Facebook"], "paper_date": "2019-06-10", "metric": "75.7"}, {"title": "Contrastive Video Representation Learning via Adversarial Perturbations@@@ADL+ResNet+IDT", "authors": ["Jue Wang", "Anoop Cherian"], "affiliations": ["Australian National University", "Mitsubishi Electric Research Laboratories"], "paper_date": "2018-07-24", "metric": "74.3"}, {"title": "Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition@@@Optical Flow Guided Feature", "authors": ["Shuyang Sun", "Zhanghui Kuang", "Lu Sheng", "Wanli Ouyang", "Wei Zhang"], "affiliations": ["University of Sydney", "", "The Chinese University of Hong Kong", "University of Sydney", "SenseTime"], "paper_date": "2017-11-29", "metric": "74.2"}, {"title": "Spatiotemporal Multiplier Networks for Video Action Recognition@@@STM Network+IDT", "authors": ["Christoph Feichtenhofer", "Axel Pinz", "Richard P. Wildes"], "affiliations": ["", "VRVis", "York University"], "paper_date": "2017-07-01", "metric": "72.2"}, {"title": "STM: SpatioTemporal and Motion Encoding for Action Recognition@@@STM (ImageNet+Kinetics pretrain)", "authors": ["Boyuan Jiang", "Mengmeng Wang", "Weihao Gan", "Wei Wu", "Junjie Yan"], "affiliations": ["Zhejiang University", "SenseTime", "SenseTime", "SenseTime", "SenseTime"], "paper_date": "2019-08-07", "metric": "72.2"}, {"title": "Attention Distillation for Learning Video Representations@@@Prob-Distill", "authors": ["Miao Liu", "Xin Chen", "Yun Zhang", "Yin Li", "James M. Rehg"], "affiliations": ["Georgia Institute of Technology", "", "Georgia Institute of Technology", "University of Wisconsin-Madison", "Georgia Institute of Technology"], "paper_date": "2019-04-05", "metric": "72.0"}, {"title": "Learning spatio-temporal representations with temporal squeeze pooling@@@TesNet (ImageNet pretrained)", "authors": ["Guoxi Huang", "Adrian G. Bors"], "affiliations": ["University of York", "University of York"], "paper_date": "2020-02-11", "metric": "71.5"}, {"title": "Hierarchical Feature Aggregation Networks for Video Action Recognition@@@HF-ECOLite (ImageNet+Kinetics pretrain)", "authors": ["Swathikiran Sudhakaran", "Sergio Escalera", "Oswald Lanz"], "affiliations": ["", "", "University of Barcelona"], "paper_date": "2019-05-29", "metric": "71.13"}, {"title": "TS-LSTM and Temporal-Inception: Exploiting Spatiotemporal Dynamics for Activity Recognition@@@TS-LSTM", "authors": ["Chih-Yao Ma", "Min-Hung Chen", "Zsolt Kira", "Ghassan AlRegib"], "affiliations": ["Georgia Institute of Technology", "Georgia Institute of Technology", "Georgia Tech Research Institute", "Georgia Institute of Technology"], "paper_date": "2017-03-30", "metric": "69"}, {"title": "Convolutional Two-Stream Network Fusion for Video Action Recognition@@@S:VGG-16, T:VGG-16", "authors": ["Christoph Feichtenhofer", "Axel Pinz", "Andrew Zisserman"], "affiliations": ["Graz University of Technology", "Graz University of Technology", "University of Oxford"], "paper_date": "2016-04-22", "metric": "65.4"}, {"title": "Long-term Temporal Convolutions for Action Recognition@@@LTC", "authors": ["G\u00fcl Varol", "Ivan Laptev", "Cordelia Schmid"], "affiliations": ["\u00c9cole Normale Sup\u00e9rieure", "\u00c9cole Normale Sup\u00e9rieure", "French Institute for Research in Computer Science and Automation"], "paper_date": "2016-04-15", "metric": "64.8"}, {"title": "R-STAN: Residual Spatial-Temporal Attention Network for Action Recognition@@@R-STAN-50", "authors": ["Quanle Liu", "Xiangjiu Che", "Mei Bie"], "affiliations": ["Jilin University", "Jilin University", "Jilin University"], "paper_date": "2019-06-19", "metric": "62.8"}, {"title": "SUSiNet: See, Understand and Summarize it@@@SUSiNet (multi, Kinetics pretrained)", "authors": ["Petros Koutras", "Petros Maragos"], "affiliations": ["National Technical University of Athens", "National Technical University of Athens"], "paper_date": "2018-12-03", "metric": "62.7"}, {"title": "Two-Stream Convolutional Networks for Action Recognition in Videos@@@Two-stream", "authors": ["Karen Simonyan", "Andrew Zisserman"], "affiliations": ["University of Oxford", "University of Oxford"], "paper_date": "2014-06-09", "metric": "59.4"}, {"title": "R-STAN: Residual Spatial-Temporal Attention Network for Action Recognition@@@R-STAN-152", "authors": ["Quanle Liu", "Xiangjiu Che", "Mei Bie"], "affiliations": ["Jilin University", "Jilin University", "Jilin University"], "paper_date": "2019-06-19", "metric": "55.16"}, {"title": "DistInit: Learning Video Representations Without a Single Labeled Video@@@R(2+1)D-18 (DistInit pretraining)", "authors": ["Rohit Girdhar", "Du Tran", "Lorenzo Torresani", "Deva Ramanan"], "affiliations": ["Carnegie Mellon University", "Facebook", "Facebook", "Carnegie Mellon University"], "paper_date": "2019-01-26", "metric": "54.8"}, {"title": "Towards Universal Representation for Unseen Action Recognition@@@CD-UAR", "authors": ["Yi Zhu", "Yang Long", "Yu Guan", "Shawn Newsam", "Ling Shao"], "affiliations": ["University of California, Merced", "Newcastle University", "Newcastle University", "University of California, Merced", "University of East Anglia"], "paper_date": "2018-03-22", "metric": "51.8"}, {"title": "Self-supervised Spatio-temporal Representation Learning for Videos by Predicting Motion and Appearance Statistics@@@Pretrained on Kinetics", "authors": ["Jiangliu Wang", "Jianbo Jiao", "Linchao Bao", "Shengfeng He", "Yunhui Liu", "Yun-Hui Liu", "Wei Liu"], "affiliations": ["The Chinese University of Hong Kong", "University of Oxford", "Tencent", "South China University of Technology", "The Chinese University of Hong Kong", "The Chinese University of Hong Kong", "Tencent"], "paper_date": "2019-04-07", "metric": "33.4"}]